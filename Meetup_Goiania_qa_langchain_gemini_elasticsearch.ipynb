{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2a3143e8-3949-4ecc-905c-8333a43c9c87",
      "metadata": {
        "id": "2a3143e8-3949-4ecc-905c-8333a43c9c87"
      },
      "source": [
        "# Meetup Goiania - Question Answering using Gemini, Langchain & Elasticsearch\n",
        "\n",
        "This tutorial demonstrates how to use the [Gemini API](https://ai.google.dev/docs) to create [embeddings](https://ai.google.dev/docs/embeddings_guide) and store them in Elasticsearch. We will learn how to connect Gemini to private data stored in Elasticsearch and build question/answer capabilities over it using [LangChian](https://python.langchain.com/docs/get_started/introduction)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68c5e34d-28f9-4195-9f9c-2a8aec1effe6",
      "metadata": {
        "id": "68c5e34d-28f9-4195-9f9c-2a8aec1effe6"
      },
      "source": [
        "## setup\n",
        "\n",
        "* Elastic Credentials - Create an [Elastic Cloud deployment](https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud) to get all Elastic credentials (`ELASTIC_CLOUD_ID`, `ELASTIC_API_KEY`).\n",
        "\n",
        "* `GOOGLE_API_KEY` - To use the Gemini API, you need to [create an API key in Google AI Studio](https://ai.google.dev/tutorials/setup)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8e9a58a-942f-4039-96c0-b276d5b8a97f",
      "metadata": {
        "id": "b8e9a58a-942f-4039-96c0-b276d5b8a97f"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c4781ec-06a5-48dd-963e-fb832b3f7ca2",
      "metadata": {
        "id": "5c4781ec-06a5-48dd-963e-fb832b3f7ca2"
      },
      "outputs": [],
      "source": [
        "pip install -q -U google-generativeai langchain-elasticsearch langchain langchain_google_genai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "851db243-ca7d-4a7c-a93b-d22ab149a1bb",
      "metadata": {
        "id": "851db243-ca7d-4a7c-a93b-d22ab149a1bb"
      },
      "source": [
        "## Import packages and credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26e7f569-c680-447b-9246-b5140ff47b6b",
      "metadata": {
        "id": "26e7f569-c680-447b-9246-b5140ff47b6b"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "from urllib.request import urlopen\n",
        "\n",
        "from langchain_elasticsearch import ElasticsearchStore\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2f68db5-21ac-47b0-941b-1d816b586e18",
      "metadata": {
        "id": "b2f68db5-21ac-47b0-941b-1d816b586e18"
      },
      "source": [
        "## Get Credentials"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6GQkDn44ZUu",
        "outputId": "a657d2c6-1d36-42c9-ca38-0a0ae9f8ac31"
      },
      "id": "r6GQkDn44ZUu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dcX04p56tv5",
        "outputId": "94cd6b71-1837-4752-eb21-530e9fa5fb7b"
      },
      "id": "7dcX04p56tv5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Substitua 'path/to/your/.env' pelo caminho correto até o seu arquivo .env no Google Drive\n",
        "env_path = '/content/drive/MyDrive/@Blogs/04-Advent-2023/env_advent'\n",
        "load_dotenv(env_path)\n",
        "\n",
        "# OpenAI API Key\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "OPENAI_API_URL = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n",
        "# Google API\n",
        "google_api_key = os.getenv('google_api_key')\n",
        "\n",
        "\n",
        "# Elastic cloud credentials\n",
        "es_cloud_id = os.getenv('cloud_id')\n",
        "es_user = os.getenv('cloud_user')\n",
        "es_pass = os.getenv('cloud_pass')\n",
        "\n",
        "ELASTIC_API_KEY = \"your_elastic_api_key\"\n",
        "ELASTIC_CLOUD_ID = es_cloud_id\n"
      ],
      "metadata": {
        "id": "4XfRvpxq4NGK"
      },
      "id": "4XfRvpxq4NGK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "543d27f4-2c53-4726-a324-716900d72338",
      "metadata": {
        "id": "543d27f4-2c53-4726-a324-716900d72338"
      },
      "outputs": [],
      "source": [
        "#os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Google API Key :\")\n",
        "#ELASTIC_API_KEY = getpass(\"Elastic API Key :\")\n",
        "#ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID :\")\n",
        "elastic_index_name = \"gemini-gyn-qa-json\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = google_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8bd47b9-b946-46d1-ba02-adbda118415a",
      "metadata": {
        "id": "e8bd47b9-b946-46d1-ba02-adbda118415a"
      },
      "source": [
        "## Add documents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ler PDF"
      ],
      "metadata": {
        "id": "De-_xEoJjw9m"
      },
      "id": "De-_xEoJjw9m"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzHpfAbdmzOo",
        "outputId": "9805ef65-33c6-4022-9c60-960e740e8452"
      },
      "id": "bzHpfAbdmzOo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "filename = \"/content/drive/MyDrive/@MyPresentations/MeetupGoiania2024/lava_pt.pdf\"\n",
        "loader = PyPDFLoader(filename)\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "bfspJYRijzzU"
      },
      "id": "bfspJYRijzzU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EP09cernK_a",
        "outputId": "cc2e6c39-8e33-4cd1-c650-8a7be460045b"
      },
      "id": "_EP09cernK_a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page = pages[0]\n",
        "page.metadata\n",
        "page"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_DKm2LSndL_",
        "outputId": "6099de49-0c41-4e76-8fc1-094573321be8"
      },
      "id": "0_DKm2LSndL_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Lavadora de roupas\\nManual do usuário\\nWD10M4***** / WD85M4*****\\nWD10M44530W(127V)_03786S-00_BPT.indd   1 2017/5/24   9:43:37', metadata={'source': '/content/drive/MyDrive/@MyPresentations/MeetupGoiania2024/lava_pt.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(page.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEsyLpd3nxOQ",
        "outputId": "9795e7b5-5b78-452c-db4e-1f56d9d00e4b"
      },
      "id": "GEsyLpd3nxOQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lavadora de roupas\n",
            "Manual do usuário\n",
            "WD10M4***** / WD85M4*****\n",
            "WD10M44530W(127V)_03786S-00_BPT.indd   1 2017/5/24   9:43:37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd04e921-206e-4c8b-937a-277d2c5a02e6",
      "metadata": {
        "id": "bd04e921-206e-4c8b-937a-277d2c5a02e6"
      },
      "source": [
        "### Let's download the sample dataset and deserialize the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44a5b79d-326e-4317-82a3-7918a11ff7b7",
      "metadata": {
        "id": "44a5b79d-326e-4317-82a3-7918a11ff7b7"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/ashishtiwari1993/langchain-elasticsearch-RAG/main/data.json\"\n",
        "\n",
        "response = urlopen(url)\n",
        "\n",
        "workplace_docs = json.loads(response.read())\n",
        "workplace_docs = pages\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workplace_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySe5kGC-pqFD",
        "outputId": "cdbb3523-1eba-41e8-bee6-6e9c7a66b1f8"
      },
      "id": "ySe5kGC-pqFD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Lavadora de roupas\\nManual do usuário\\nWD10M4***** / WD85M4*****\\nWD10M44530W(127V)_03786S-00_BPT.indd   1 2017/5/24   9:43:37', metadata={'source': '/content/drive/MyDrive/@MyPresentations/MeetupGoiania2024/lava_pt.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8591dce2-3fe6-4c87-b268-4694bb86e803",
      "metadata": {
        "id": "8591dce2-3fe6-4c87-b268-4694bb86e803"
      },
      "source": [
        "### Split Documents into Passages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3963b0db-80d5-4908-897c-bec6357adc0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3963b0db-80d5-4908-897c-bec6357adc0a",
        "outputId": "c724421b-1e15-48bd-de88-c5eddb0c57b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 245, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 288, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 204, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 281, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 249, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 285, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 298, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 270, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 224, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 288, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 260, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 290, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 251, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 242, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 275, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 277, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 284, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 285, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 324, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 328, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 280, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 221, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 330, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 292, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 240, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 232, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 324, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 353, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 471, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 400, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 607, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 440, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 788, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 547, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 635, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 440, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 464, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 372, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 866, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 361, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 471, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 288, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 619, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 257, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 310, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 310, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 282, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 230, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 213, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 395, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 270, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 224, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 292, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 231, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 277, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 253, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 323, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 201, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 232, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 238, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 305, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1120, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 397, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 320, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 567, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 300, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 217, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 271, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 264, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 340, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 383, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 243, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 344, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 225, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 208, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 420, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 299, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 310, which is longer than the specified 200\n"
          ]
        }
      ],
      "source": [
        "metadata = []\n",
        "content = []\n",
        "\n",
        "for doc in workplace_docs:\n",
        "    content.append(doc[\"content\"])\n",
        "    metadata.append(\n",
        "        {\n",
        "            \"name\": doc[\"name\"],\n",
        "            \"summary\": doc[\"summary\"],\n",
        "            \"rolePermissions\": doc[\"rolePermissions\"],\n",
        "        }\n",
        "    )\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
        "docs = text_splitter.create_documents(content, metadatas=metadata)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# metadata = []\n",
        "# content = []\n",
        "\n",
        "# for doc in workplace_docs:\n",
        "#     content.append(doc[\"content\"])\n",
        "#     metadata.append(\n",
        "#         {\n",
        "#             \"name\": doc[\"name\"],\n",
        "#             \"summary\": doc[\"summary\"],\n",
        "#             \"rolePermissions\": doc[\"rolePermissions\"],\n",
        "#         }\n",
        "#     )\n",
        "\n",
        "# text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
        "# docs = text_splitter.create_documents(content, metadatas=metadata)"
      ],
      "metadata": {
        "id": "RGehfa1Tpd8F"
      },
      "id": "RGehfa1Tpd8F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "YRtsvfQIh5_Y"
      },
      "id": "YRtsvfQIh5_Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a066d5dc-dbc9-495f-934f-bfe96e0fdeec",
      "metadata": {
        "id": "a066d5dc-dbc9-495f-934f-bfe96e0fdeec"
      },
      "source": [
        "## Index Documents into Elasticsearch using Gemini Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\", task_type=\"retrieval_document\"\n",
        ")\n",
        "\n",
        "es = ElasticsearchStore.from_documents(\n",
        "    docs,\n",
        "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
        "    es_api_key=ELASTIC_API_KEY,\n",
        "    index_name=elastic_index_name,\n",
        "    embedding=query_embedding,\n",
        ")"
      ],
      "metadata": {
        "id": "wju8adXZl0Ux"
      },
      "id": "wju8adXZl0Ux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dbdb2d55-3349-4e95-8087-68f927f0d864",
      "metadata": {
        "id": "dbdb2d55-3349-4e95-8087-68f927f0d864"
      },
      "source": [
        "## Create a retriever using Elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17920c1e-9228-42f5-893d-29b666d6f7b2",
      "metadata": {
        "id": "17920c1e-9228-42f5-893d-29b666d6f7b2"
      },
      "outputs": [],
      "source": [
        "query_embedding = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\", task_type=\"retrieval_query\"\n",
        ")\n",
        "\n",
        "# es = ElasticsearchStore(\n",
        "#     es_cloud_id=es_cloud_id,\n",
        "#     es_api_key=ELASTIC_API_KEY,\n",
        "#     embedding=query_embedding,\n",
        "#     index_name=elastic_index_name,\n",
        "# )\n",
        "\n",
        "es = ElasticsearchStore(\n",
        "    es_cloud_id=es_cloud_id,\n",
        "    index_name=elastic_index_name,\n",
        "    embedding=query_embedding,\n",
        "    es_user=es_user,\n",
        "    es_password=es_pass\n",
        ")\n",
        "\n",
        "retriever = es.as_retriever(search_kwargs={\"k\": 3})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3647d005-d70e-4c3a-b784-052b21e9f143",
      "metadata": {
        "id": "3647d005-d70e-4c3a-b784-052b21e9f143"
      },
      "source": [
        "## Format Docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04ee4d3d-09fb-4a35-bc66-8a2951c402a8",
      "metadata": {
        "id": "04ee4d3d-09fb-4a35-bc66-8a2951c402a8"
      },
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "864afb6a-a671-434a-bd30-006c79ccda24",
      "metadata": {
        "id": "864afb6a-a671-434a-bd30-006c79ccda24"
      },
      "source": [
        "## Create a Chain using Prompt Template + `gemini-pro` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4818aef7-3535-494d-a5d4-16ef6d0581af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "4818aef7-3535-494d-a5d4-16ef6d0581af",
        "outputId": "82945e14-9592-4ae0-bfdb-3e7c96269a2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Increase revenue by 20% compared to fiscal year 2023.\\nExpand market share in key segments by 15%.\\nRetain 95% of existing customers and increase customer satisfaction ratings.\\nLaunch at least two new products or services in high-demand market segments.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\\n\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain.invoke(\"what is our sales goals?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Increase revenue, expand market share,\n",
        "and strengthen customer relationships\n",
        "in our target markets."
      ],
      "metadata": {
        "id": "kI--kFU8-1hH"
      },
      "id": "kI--kFU8-1hH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_2yhUuY8NmSt"
      },
      "id": "_2yhUuY8NmSt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ITzDvuE5NmV3"
      },
      "id": "ITzDvuE5NmV3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testes"
      ],
      "metadata": {
        "id": "FAiIWUfXNmtf"
      },
      "id": "FAiIWUfXNmtf"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69nKH3xANp20"
      },
      "id": "69nKH3xANp20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF"
      ],
      "metadata": {
        "id": "OWW8--vZqM8k"
      },
      "id": "OWW8--vZqM8k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "    # Duplicate documents on purpose - messy data\n",
        "    PyPDFLoader(\"/content/drive/MyDrive/@MyPresentations/MeetupGoiania2024/lava_pt.pdf\")\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ],
      "metadata": {
        "id": "UqaYYW3IqOHa"
      },
      "id": "UqaYYW3IqOHa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")"
      ],
      "metadata": {
        "id": "d0oc8YsaqXyo"
      },
      "id": "d0oc8YsaqXyo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "FSgBhzqeqeUd"
      },
      "id": "FSgBhzqeqeUd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFc08pXGqi6o",
        "outputId": "fe479bf8-5c9d-4f8d-e368-496f328ac605"
      },
      "id": "TFc08pXGqi6o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\", task_type=\"retrieval_document\"\n",
        ")\n",
        "\n",
        "es = ElasticsearchStore.from_documents(\n",
        "    splits,\n",
        "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
        "    es_api_key=ELASTIC_API_KEY,\n",
        "    index_name=elastic_index_name,\n",
        "    embedding=query_embedding,\n",
        ")"
      ],
      "metadata": {
        "id": "pIqP7_0tqlZX"
      },
      "id": "pIqP7_0tqlZX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\", task_type=\"retrieval_query\"\n",
        ")\n",
        "\n",
        "# es = ElasticsearchStore(\n",
        "#     es_cloud_id=es_cloud_id,\n",
        "#     es_api_key=ELASTIC_API_KEY,\n",
        "#     embedding=query_embedding,\n",
        "#     index_name=elastic_index_name,\n",
        "# )\n",
        "\n",
        "es = ElasticsearchStore(\n",
        "    es_cloud_id=es_cloud_id,\n",
        "    index_name=elastic_index_name,\n",
        "    embedding=query_embedding,\n",
        "    es_user=es_user,\n",
        "    es_password=es_pass\n",
        ")\n",
        "\n",
        "retriever = es.as_retriever(search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "5hZzmVrMq14c"
      },
      "id": "5hZzmVrMq14c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "8_eqVuIZrZlg"
      },
      "id": "8_eqVuIZrZlg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the question in portuguese based only on the following context:\\n\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain.invoke(\"como funciona a maquina?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "FNq7VlQUrd2J",
        "outputId": "7c09480a-1370-4787-e2d5-15dcb1b011dc"
      },
      "id": "FNq7VlQUrd2J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Para usar a máquina, gire o seletor de ciclos para selecionar um ciclo. O visor mostrará informações sobre o ciclo atual e o tempo estimado restante, ou ainda, um código de informação quando ocorrer algum problema. Você pode pressionar a tecla Temp. para mudar a temperatura da água do ciclo atual. Também é possível pressionar a tecla Centrifugar para mudar a velocidade de centrifugação do ciclo atual.\\n\\nPara selecionar a opção de secagem adequada, pressione a tecla Nível de Secagem. Todas as opções de secagem, exceto a opção Tempo de Secagem, detectam o peso das roupas para exibir um tempo de secagem mais preciso e secá-las mais completamente. Consulte a tabela na página 40 para selecionar a opção de secagem apropriada de acordo com o tipo e a quantidade de peças e a umidade que você deseja deixar.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"O que você precisa saber sobre as instruções de segurança?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "qTkP93FdrsjG",
        "outputId": "8bc9202d-89e1-4393-8455-241d53b75c0a"
      },
      "id": "qTkP93FdrsjG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' O que você precisa saber sobre as instruções de segurança\\nLeia este manual cuidadosamente para que você saiba como operar de forma segura e eficiente os recursos e as funções abrangentes do seu novo eletrodoméstico. Mantenha-o em um lugar seguro próximo ao eletrodoméstico para consultas futuras. Utilize esse eletrodoméstico somente para os fins pretendidos, conforme descrito neste manual de instruções. As Advertências e Instruções importantes de segurança deste manual não abrangem todas as condições e situações que podem vir a ocorrer. É sua responsabilidade ter bom senso, cuidado e precaução ao instalar, cuidar e operar sua lavadora de roupas.Como as instruções de operação a seguir servem para vários modelos, as características da sua lavadora de roupas podem ser levemente diferentes daquelas descritas neste manual e nem todos os sinais de advertência serão aplicáveis. Caso tenha alguma dúvida ou comentário, entre em contato com a central de atendimento mais próxima ou encontre ajuda e informações online em www.samsung.com.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-HMOZ1yAryPZ"
      },
      "id": "-HMOZ1yAryPZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}